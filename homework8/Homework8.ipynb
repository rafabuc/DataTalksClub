{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ybVfdWeDeJoU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsAFoYEgl6X3",
        "outputId": "5e4c755d-7405-4201-bf5a-4c636e33e111"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-25 20:14:54--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-25T20%3A56%3A51Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-25T19%3A56%3A48Z&ske=2025-11-25T20%3A56%3A51Z&sks=b&skv=2018-11-09&sig=siRLrMoBwllP%2FP8vIavhoFWryZTlVHNzXH8KTiyjIQA%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDEwMzQ5NCwibmJmIjoxNzY0MTAxNjk0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.eCMh-jDu2sX29CVV0B83aByl4GWz9E4suEqhE-YObyg&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-25 20:14:54--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-25T20%3A56%3A51Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-25T19%3A56%3A48Z&ske=2025-11-25T20%3A56%3A51Z&sks=b&skv=2018-11-09&sig=siRLrMoBwllP%2FP8vIavhoFWryZTlVHNzXH8KTiyjIQA%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDEwMzQ5NCwibmJmIjoxNzY0MTAxNjk0LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.eCMh-jDu2sX29CVV0B83aByl4GWz9E4suEqhE-YObyg&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102516572 (98M) [application/octet-stream]\n",
            "Saving to: ‘data.zip.1’\n",
            "\n",
            "data.zip.1          100%[===================>]  97.77M   582MB/s    in 0.2s    \n",
            "\n",
            "2025-11-25 20:14:54 (582 MB/s) - ‘data.zip.1’ saved [102516572/102516572]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui9rNdJtmHrf",
        "outputId": "b13629ed-8bae-4ba0-dc7d-572c035c42a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "replace data/test/curly/03312ac556a7d003f7570657f80392c34.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Conv2d: 3 input channels, 32 output channels, kernel size 3\n",
        "        # Input shape: (3, 200, 200)\n",
        "        # Output shape after conv: (32, 198, 198)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # MaxPool2d: kernel size 2\n",
        "        # Output shape after pool: (32, 99, 99)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Flatten\n",
        "        # 32 * 99 * 99 = 313632\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Linear layer: 32*99*99 -> 64\n",
        "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
        "\n",
        "        # Output layer: 64 -> 1\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "        # Sigmoid activation for binary classification\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "def create_model_and_optimizer():\n",
        "    model = CNN()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "    criterion = nn.BCELoss()#nn.BCEWithLogitsLoss()\n",
        "    return model, optimizer, criterion"
      ],
      "metadata": {
        "id": "KlbwsiSOgoDc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "nn.MSELoss(): This is typically used for regression problems, not binary classification.\n",
        "nn.BCEWithLogitsLoss(): This is also a Binary Cross-Entropy Loss, but it expects raw, unscaled scores (logits) as input, and it internally applies the sigmoid function for numerical stability. If your SimpleCNN's forward method returned self.fc2(x) directly (without the torch.sigmoid), then nn.BCEWithLogitsLoss() would be the preferred and more numerically stable choice.\n",
        "nn.CrossEntropyLoss(): This is primarily used for multi-class classification problems, not binary classification, and it also expects logits as input.\n",
        "nn.CosineEmbeddingLoss(): This loss function is used for learning embeddings and measuring the similarity between two inputs, which is not applicable here.\n",
        "So, while nn.BCEWithLogitsLoss() is conceptually close, given your current model's architecture which includes sigmoid in the forward pass, nn.BCELoss() is the appropriate loss function to use.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "ICI6wRsMjhWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 1: Using torchsummary (install with: pip install torchsummary)\n",
        "from torchsummary import summary\n",
        "model, optimizer, criterion = create_model_and_optimizer()\n",
        "#print(model)\n",
        "#print(optimizer)"
      ],
      "metadata": {
        "id": "CxMp7ALNtmX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Convolutional Layer\n",
        "        # Input channels: 3 (RGB image)\n",
        "        # Output channels: 32\n",
        "        # Kernel size: (3, 3)\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3))\n",
        "        # Max Pooling Layer\n",
        "        # Kernel size: (2, 2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "        # Calculate the size of the flattened features after conv and pool\n",
        "        # Input H, W = 200, 200\n",
        "        # After conv1: H = (200 - 3 + 0)/1 + 1 = 198, W = (200 - 3 + 0)/1 + 1 = 198\n",
        "        # After pool: H = 198 / 2 = 99, W = 198 / 2 = 99\n",
        "        # Flattened features: 32 (channels) * 99 (H) * 99 (W) = 313632\n",
        "        self.fc1 = nn.Linear(32 * 99 * 99, 64)\n",
        "        # Output layer for binary classification\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolution and ReLU activation\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # Apply max pooling\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Flatten the feature map into a vector\n",
        "        # x.size(0) gets the batch size, -1 infers the remaining dimension\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Apply first fully connected layer and ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Apply second fully connected (output) layer with Sigmoid for binary classification\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "def create_model_and_optimizer_v2():\n",
        "    model = CNN()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
        "    criterion = nn.BCELoss()#nn.BCEWithLogitsLoss()\n",
        "    return model, optimizer, criterion\n"
      ],
      "metadata": {
        "id": "bsYNupEttdx_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchsummary import summary\n",
        "model, optimizer, criterion = create_model_and_optimizer()"
      ],
      "metadata": {
        "id": "xyM2pxvljZj9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    model.to('cuda')\n",
        "\n",
        "summary(model, input_size=(3, 200, 200))\n",
        "\n",
        "# Option 2: Manual counting\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqy0s69MkW7W",
        "outputId": "7a139c54-523a-460d-9a0d-f71d8d8c6d76"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 198, 198]             896\n",
            "              ReLU-2         [-1, 32, 198, 198]               0\n",
            "         MaxPool2d-3           [-1, 32, 99, 99]               0\n",
            "           Flatten-4               [-1, 313632]               0\n",
            "            Linear-5                   [-1, 64]      20,072,512\n",
            "              ReLU-6                   [-1, 64]               0\n",
            "            Linear-7                    [-1, 1]              65\n",
            "           Sigmoid-8                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 20,073,473\n",
            "Trainable params: 20,073,473\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.46\n",
            "Forward/backward pass size (MB): 23.93\n",
            "Params size (MB): 76.57\n",
            "Estimated Total Size (MB): 100.96\n",
            "----------------------------------------------------------------\n",
            "Total parameters: 20073473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ) # ImageNet normalization\n",
        "])"
      ],
      "metadata": {
        "id": "m0XJxyJZlkzG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Instantiate model, optimizer, and criterion\n",
        "model, optimizer, criterion = create_model_and_optimizer()\n",
        "model.to(device)\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder('data/train', transform=train_transforms)\n",
        "validation_dataset = datasets.ImageFolder('data/test', transform=train_transforms)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 20 # Changed batch size to 20\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "9d6GOOuBmP5Q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
        "        predicted = (outputs > 0.5).float() # outputs already have sigmoid applied in SimpleCNN\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = correct_train / total_train\n",
        "    history['loss'].append(epoch_loss)\n",
        "    history['acc'].append(epoch_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validation_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            labels = labels.float().unsqueeze(1)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * images.size(0)\n",
        "            predicted = (outputs > 0.5).float()\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
        "    val_epoch_acc = correct_val / total_val\n",
        "    history['val_loss'].append(val_epoch_loss)\n",
        "    history['val_acc'].append(val_epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
        "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxeXtdhfnT-3",
        "outputId": "1538d262-93af-4dab-bdd1-91090326b497"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6512, Acc: 0.6188, Val Loss: 0.6450, Val Acc: 0.6119\n",
            "Epoch 2/10, Loss: 0.5314, Acc: 0.7238, Val Loss: 0.6370, Val Acc: 0.6617\n",
            "Epoch 3/10, Loss: 0.5057, Acc: 0.7450, Val Loss: 0.5866, Val Acc: 0.6517\n",
            "Epoch 4/10, Loss: 0.4690, Acc: 0.7662, Val Loss: 0.6053, Val Acc: 0.6517\n",
            "Epoch 5/10, Loss: 0.3914, Acc: 0.8263, Val Loss: 0.5877, Val Acc: 0.6915\n",
            "Epoch 6/10, Loss: 0.3291, Acc: 0.8525, Val Loss: 0.8346, Val Acc: 0.6816\n",
            "Epoch 7/10, Loss: 0.3731, Acc: 0.8325, Val Loss: 0.6629, Val Acc: 0.6965\n",
            "Epoch 8/10, Loss: 0.2460, Acc: 0.9025, Val Loss: 0.6110, Val Acc: 0.7363\n",
            "Epoch 9/10, Loss: 0.2911, Acc: 0.8650, Val Loss: 0.5319, Val Acc: 0.7164\n",
            "Epoch 10/10, Loss: 0.1603, Acc: 0.9450, Val Loss: 0.6369, Val Acc: 0.7562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "median_train_accuracy = np.median(history['acc'])\n",
        "print(f\"3 Median of training accuracy for all epochs: {median_train_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofecZ9tXrXGR",
        "outputId": "cc92dd80-c80b-4c20-bc3b-e86a66086b5c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 Median of training accuracy for all epochs: 0.8294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e63580e",
        "outputId": "d01cd307-6495-429e-bba8-efd1c2fc80c4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "std_dev_train_loss = np.std(history['loss'])\n",
        "print(f\"4 Standard deviation of training loss for all epochs: {std_dev_train_loss:.4f}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 Standard deviation of training loss for all epochs: 0.1396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "mean_val_loss = np.mean(history['val_loss'])\n",
        "print(f\"5 Mean of validation loss for all epochs: {mean_val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxk6Jq3Fuv4T",
        "outputId": "3d2157c7-91f8-4cd2-b57f-436ef815592c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 Mean of validation loss for all epochs: 0.6339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the validation accuracy for the last 5 epochs\n",
        "last_5_val_acc = history['val_acc'][-5:]\n",
        "\n",
        "# Calculate the average of these accuracies\n",
        "average_val_acc_last_5_epochs = np.mean(last_5_val_acc)\n",
        "\n",
        "print(f\"6 Average of validation accuracy for the last 5 epochs: {average_val_acc_last_5_epochs:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCDO952Wr6I_",
        "outputId": "302f5055-5eee-4266-961d-0b94947a4906"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 Average of validation accuracy for the last 5 epochs: 0.7174\n"
          ]
        }
      ]
    }
  ]
}